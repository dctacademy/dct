{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment \"Assignment\" System for DCT Academy's Code Platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import scipy.sparse as sparse\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "import random\n",
    "import implicit\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating list of dataframe of all tables, a dictionary mapping to corresponding dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of all the tables and their columns\n",
    "table_columns = {}\n",
    "\n",
    "# Dictionary of all dataframes mapped with table names\n",
    "df_all = {}\n",
    "\n",
    "# List of all dataframes of all tables\n",
    "df_list = []\n",
    "\n",
    "request_tables = ['submissions', 'assignments', 'tags', 'taggings']\n",
    "\n",
    "for table in request_tables:\n",
    "    url = 'http://code.dctacademy.com/api/v1/ml/data/' + table + '?key=6eccc23db96ed84fce329e0d20bdacb4'\n",
    "    response = requests.get(url)\n",
    "#     print(response.status_code, response.reason)\n",
    "    df_all[table] = pd.read_json(response.content)\n",
    "    \n",
    "model_path = '../ml-api/model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all student/user assignments\n",
    "### Merge submissions, assignments, taggings, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions = df_all['submissions'] \\\n",
    "    .merge(df_all['assignments'], left_on='assignment_id', right_on='id', suffixes=('_submissions', '_assignments')) \\\n",
    "    .merge(df_all['taggings'], left_on='id_assignments', right_on='taggable_id', suffixes=('_sub_ass', '_taggings')) \\\n",
    "    .merge(df_all['tags'], left_on='tag_id', right_on='id', suffixes=('_sub_ass_tag', '_tags')) \n",
    "\n",
    "submission_assignments = df_all['submissions'] \\\n",
    "    .merge(df_all['assignments'], left_on='assignment_id', right_on='id', suffixes=('_submissions', '_assignments'))\n",
    "\n",
    "user_submissions.drop(['statement', 'output', 'language', 'created_at_submissions', 'updated_at_submissions', 'is_checked', 'body', 'url', \n",
    "                       'created_at_assignments', 'updated_at_assignments', 'pass', 'fail', 'tagger_type', 'created_at', 'total', 'practice_id', \n",
    "                       'assignment_id', 'user_id_assignments', 'code_assignments', 'tagger_id', 'tag_id', 'source', 'input_size',\n",
    "                       'approved', 'function_name', 'context', 'id_sub_ass_tag', 'taggings_count', 'is_allowed'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['code_submissions', 'id_submissions', 'points_submissions',\n",
       "       'time_in_seconds', 'user_id_submissions', 'display_helper',\n",
       "       'id_assignments', 'is_front_end', 'minutes', 'points_assignments',\n",
       "       'title', 'taggable_id', 'taggable_type', 'id_tags', 'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_submissions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions = user_submissions[user_submissions['taggable_type'] == 'Assignment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning tags and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions['name'] = user_submissions['name'].str.strip().replace('/',',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       6352.000000\n",
       "mean      104247.813287\n",
       "std       488903.442711\n",
       "min            0.000000\n",
       "25%          372.000000\n",
       "50%         1112.500000\n",
       "75%         5324.000000\n",
       "max      5727785.000000\n",
       "Name: time_in_seconds, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_submissions['time_in_seconds'] = user_submissions['time_in_seconds'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all submissions with time greater than 100,000 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     6352.000000\n",
       "mean      7089.782746\n",
       "std      17991.244558\n",
       "min          0.000000\n",
       "25%        372.000000\n",
       "50%       1112.250000\n",
       "75%       2306.000000\n",
       "max      95959.000000\n",
       "Name: time_in_seconds, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = user_submissions['time_in_seconds'].median() \n",
    "user_submissions.loc[user_submissions.time_in_seconds > 100000, 'time_in_seconds'] = np.nan\n",
    "user_submissions.fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting submissions which are greater than 0 and lesser than 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions = user_submissions[(user_submissions['time_in_seconds'] != 0) & (user_submissions['time_in_seconds'] < 100000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the confidence column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = df_all['tags']['name'].apply(lambda x:x.lower()).unique()\n",
    "tags.sort()\n",
    "tag_points = [10, 5, 15, 20, 15, 10, 25, 50, 20, 20, 100, 15, 20, 5, 5, 5, 75, 20, 15, 15, 5, 5, 10, 15, 5]\n",
    "\n",
    "mapping = dict(zip(tags, tag_points))\n",
    "\n",
    "assignment_tags = user_submissions.groupby(['id_assignments']).aggregate(lambda x: list(set(x)))['name'].to_frame()\n",
    "assignment_points = assignment_tags['name'].apply(lambda x:[mapping[i] for i in x]).apply(lambda x:sum(x)).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_submissions['assignment_points'] = user_submissions['id_assignments'].apply(lambda x: assignment_points.loc[x])\n",
    "user_submissions['confidence'] = ((user_submissions['points_submissions'] / user_submissions['points_assignments']) + (user_submissions['minutes'] / (user_submissions['time_in_seconds'] / 60))) * user_submissions['assignment_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_submissions</th>\n",
       "      <th>id_assignments</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>103.448276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>168.474576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>97.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>47.974414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>10.786517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id_submissions  id_assignments  confidence\n",
       "0                    3              23  103.448276\n",
       "1                    3              30  168.474576\n",
       "2                    3              33   97.222222\n",
       "3                    3              34   47.974414\n",
       "4                    3              44   10.786517"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_submissions = user_submissions.groupby(['user_id_submissions', 'id_assignments']).aggregate(lambda x:max(set(x)))['confidence'].reset_index()\n",
    "user_submissions.to_csv(model_path + 'user_submissions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating sparse matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user_id_submissions</th>\n",
       "      <th>3</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>...</th>\n",
       "      <th>66</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>76</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>84</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_assignments</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56.697248</td>\n",
       "      <td>204.383562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.267398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>45.317221</td>\n",
       "      <td>18.796992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.29927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.243449</td>\n",
       "      <td>33.844340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.836097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user_id_submissions   3          13         14   17   18   19   20       21  \\\n",
       "id_assignments                                                                \n",
       "14                   0.0   0.000000   0.000000  0.0  0.0  0.0  0.0  0.00000   \n",
       "15                   0.0   0.000000   0.000000  0.0  0.0  0.0  0.0  0.00000   \n",
       "17                   0.0  45.317221  18.796992  0.0  0.0  0.0  0.0  7.29927   \n",
       "20                   0.0   0.000000   0.000000  0.0  0.0  0.0  0.0  0.00000   \n",
       "22                   0.0   0.000000   0.000000  0.0  0.0  0.0  0.0  0.00000   \n",
       "\n",
       "user_id_submissions   22   23 ...          66          68   69         70  \\\n",
       "id_assignments                ...                                           \n",
       "14                   0.0  0.0 ...   56.697248  204.383562  0.0  20.267398   \n",
       "15                   0.0  0.0 ...    0.000000    0.000000  0.0   0.000000   \n",
       "17                   0.0  0.0 ...   16.243449   33.844340  0.0  12.836097   \n",
       "20                   0.0  0.0 ...    0.000000    0.000000  0.0   0.000000   \n",
       "22                   0.0  0.0 ...    0.000000    0.000000  0.0   0.000000   \n",
       "\n",
       "user_id_submissions   71   76   78   79   80   84  \n",
       "id_assignments                                     \n",
       "14                   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15                   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "17                   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "20                   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "22                   0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_submissions_pivot = user_submissions.pivot_table(values='confidence', index='id_assignments', columns='user_id_submissions', fill_value=0)\n",
    "user_submissions_pivot.to_csv(model_path + 'user_submissions_pivot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.3391812865497"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_size = user_submissions_pivot.shape[0] * user_submissions_pivot.shape[1] \n",
    "interactions = user_submissions_pivot.astype(bool).sum(axis=0).sum()\n",
    "sparsity = 100 * (1 - (interactions / matrix_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Training and Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hide a certain percentage of the user/item interactions from the model_als during the training phase chosen at random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will take in the original user-assignment matrix and \"mask\" a percentage of the original id_assignments where a user-assignment interaction has taken place for use as a test set. The test set will contain all of the original assignments, while the training set replaces the specified percentage of them with a zero in the original assignments matrix. \n",
    "    \n",
    "* **parameters**: \n",
    "    \n",
    "    1. **id_assignments** - the original id_assignments matrix from which you want to generate a train/test set. Test is just a complete copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    2. **pct_test** - The percentage of user-assignment interactions where an interaction took place that you want to mask in the training set for later comparison to the test set, which contains all of the original id_assignments. \n",
    "    \n",
    "* **returns**:\n",
    "    \n",
    "    1. **training_set** - The altered version of the original data with a certain percentage of the user-assignment pairs that originally had interaction set back to zero.\n",
    "    \n",
    "    2. **test_set** - A copy of the original id_assignments matrix, unaltered, so it can be used to see how the rank order compares with the actual interactions.\n",
    "    \n",
    "    3. **user_inds** - From the randomly selected user-assignment indices, which user rows were altered in the training data. This will be necessary later when evaluating the performance via AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(id_assignments, pct_test = 0.2):\n",
    "    # Make a copy of the original set to be the test set. \n",
    "    test_set = id_assignments.copy() \n",
    "    \n",
    "    # Store the test set as a binary preference matrix\n",
    "    test_set[test_set != 0] = 1 \n",
    "    \n",
    "    # Make a copy of the original data we can alter as our training set. \n",
    "    training_set = id_assignments.copy() \n",
    "    \n",
    "    # Find the indices in the assignments data where an interaction exists\n",
    "    nonzero_inds = training_set.nonzero() \n",
    "    \n",
    "    # Zip these pairs together of user,item index into list\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) \n",
    "    \n",
    "    # Set the random seed to zero for reproducibility\n",
    "    random.seed(0) \n",
    "    \n",
    "    # Round the number of samples needed to the nearest integer\n",
    "    num_samples = int(np.ceil(pct_test * len(nonzero_pairs))) \n",
    "    \n",
    "    # Sample a random number of user-item pairs without replacement\n",
    "    samples = random.sample(nonzero_pairs, num_samples) \n",
    "    \n",
    "    # Get the user row indices\n",
    "    user_inds = [index[0] for index in samples] \n",
    "    \n",
    "    # Get the item column indices\n",
    "    assignment_inds = [index[1] for index in samples] \n",
    "    \n",
    "    # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set[user_inds, assignment_inds] = 0 \n",
    "    \n",
    "    # Get rid of zeros in sparse array storage after update to save space\n",
    "    training_set.eliminate_zeros() \n",
    "    \n",
    "    # Output the unique list of user rows that were altered  \n",
    "    return training_set, test_set, list(set(user_inds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_train, assignment_test, assignment_users_altered = make_train(sparse.csr_matrix(user_submissions_pivot.values), pct_test = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model_als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 50.0/50 [00:00<00:00, 1285.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../ml-api/model/user_assignments_model_als.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_als = implicit.als.AlternatingLeastSquares(factors=64, regularization = 0.1, iterations = 50)\n",
    "model_als.fit(assignment_train)\n",
    "\n",
    "user_vecs_als = model_als.item_factors\n",
    "item_vecs_als = model_als.user_factors\n",
    "\n",
    "filename = 'user_assignments_model_als.pkl'\n",
    "joblib.dump(model_als, model_path + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 50/50 [00:00<00:00, 93.54it/s, correct=90.56%, skipped=41.90%]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../ml-api/model/user_assignments_model_bayes.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bayes = implicit.bpr.BayesianPersonalizedRanking(factors=95, learning_rate=0.2, regularization = 0.1, iterations = 50)\n",
    "model_bayes.fit(assignment_train)\n",
    "\n",
    "user_vecs_bayes = model_bayes.item_factors\n",
    "item_vecs_bayes = model_bayes.user_factors\n",
    "\n",
    "filename = 'user_assignments_model_bayes.pkl'\n",
    "joblib.dump(model_bayes, model_path + filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
